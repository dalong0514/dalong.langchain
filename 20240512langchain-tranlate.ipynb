{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting...\n",
      "\n",
      "Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Here we examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. Generative AI methods can create designs, such as small-molecule drugs and proteins, by analysing diverse data modalities, including images and sequences. We discuss how these methods can help scientists throughout the scientific process and the central issues that remain despite such advances. Both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain. These issues cut across scientific disciplines and require developing foundational algorithmic approaches that can contribute to scientific understanding or acquire it autonomously, making them critical areas of focus for AI innovation.\n",
      "\n",
      "The foundation for forming scientific insights and theories is laid by how data are collected, transformed and understood. The rise of deep learning in the early 2010s has significantly expanded the scope and ambition of these scientific discovery processes1. Artificial intelligence (AI) is increasingly used across scientific disciplines to integrate massive datasets, refine measurements, guide experimentation, explore the space of theories compatible with the data, and provide actionable and reliable models integrated with scientific workflows for autonomous discovery. Data collection and analysis are fundamental to scientific understanding and discovery, two of the central aims in science2, and quantitative methods and emerging technologies, from physical instruments such as microscopes to research techniques such as bootstrapping, have long been used to reach these aims3. The introduction of digitization in the 1950s paved the way for the general use of computing in scientific research. The rise of data science since the 2010s has enabled AI to provide valuable guidance by identifying scientifically relevant patterns from large datasets. \n",
      "\n",
      "Although scientific practices and procedures vary across stages of scientific research, the development of AI algorithms cuts across traditionally isolated disciplines (Fig. 1). Such algorithms can enhance the design and execution of scientific studies. They are becoming approach is incorporating scientific knowledge into AI models by including information about fundamental equations, such as the laws of physics or principles of molecular structure and binding in protein folding. Such inductive biases can enhance AI models by reducing the number of training examples needed to achieve the same level of accuracy10 and scaling analyses to a vast space of unexplored scientific hypotheses11.\n",
      "人工智能（AI）正在日益成为科学发现的重要助力，它不仅加速了研究进程，还帮助科学家们提出假设、规划实验、处理和解读庞大的数据集，并从中获得仅凭传统科学方法难以触及的深刻见解。过去十年中，自监督学习和几何深度学习等技术的突破，使得模型能够在海量未标记数据上进行训练，同时利用科学数据的内在结构提高模型的精确度和效率。生成式 AI 技术更是能够分析包括图像和序列在内的多种数据类型，从而设计出如小分子药物和蛋白质等复杂结构。我们探讨了这些技术如何贯穿整个科学研究过程，为科学家提供支持，同时也指出了尽管取得了这些进展，但仍需面对的关键问题。AI 工具的开发者和使用者都需要更深入地了解何时以及如何改进这些方法，同时也要解决因数据质量不佳和数据管理不当带来的挑战。这些问题横跨各个科学领域，需要开发能够促进科学理解或自主获取知识的基础算法，这使得它们成为 AI 创新的关键领域。\n",
      "\n",
      "科学见解和理论的形成，其根基在于数据的采集、转换和理解。2010 年代初，深度学习的兴起极大地扩展了科学发现过程的广度和深度。AI 技术如今在多个科学领域中被广泛应用，用于整合庞大的数据集，精炼测量结果，指导实验设计，探索与数据相符的理论空间，并为自主发现提供与科学工作流程紧密结合的实用且可靠的模型。数据收集和分析是科学理解和发现的核心，而定量方法和新兴技术，如显微镜等物理仪器和自助法等研究技术，一直是实现这些目标的重要工具。20 世纪 50 年代的数字化革命为科学研究中计算技术的广泛应用奠定了基础。自 2010 年代以来，数据科学的兴起使得 AI 能够从大型数据集中识别出科学相关的模式，为科学研究提供宝贵的指导。\n",
      "\n",
      "尽管科学实践和程序在科学研究的各个阶段有所差异，但 AI 算法的发展已经打破了传统学科之间的界限（图 1）。这些算法正在成为科学研究设计和执行的强大工具。它们通过将科学知识融入 AI 模型中，例如包含物理定律或蛋白质折叠中的分子结构和结合原理等基本方程，来增强模型的性能。这种归纳偏差不仅减少了达到相同准确度所需的训练样本数量，还使得分析能够扩展到大量尚未探索的科学假设领域。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import api_key as api\n",
    "import common_tools as common_tools\n",
    "\n",
    "api_key = api.deepseek_api_key()\n",
    "base_url= 'https://api.deepseek.com/v1'\n",
    "model_name='deepseek-chat'\n",
    "\n",
    "prompt_content = api.read_file('./translate_prompt.md')\n",
    "origin_content = api.read_file('./origin_content.md')\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_content),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    "    model_name=model_name,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "print('waiting...\\n')\n",
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"input\": origin_content})\n",
    "out_content = common_tools.extract_translation(response)\n",
    "out_content = common_tools.modify_text(out_content)\n",
    "# 使用format()方法拼接字符串并加入换行符\n",
    "result = \"{}\\n\\n{}\".format(origin_content, out_content)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting...\n",
      "\n",
      "Time Used: 20.0min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = 100\n",
    "print('waiting...\\n')\n",
    "end_time = 1300\n",
    "print('Time Used: ' + str((end_time - start_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'common_tools' from '/Users/Daglas/dalong.llm/dalong.langchain/common_tools.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(common_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The large language models (LLMs) are than anything we have seen in Processing (NLP) before. The more Natural GPT series models [ Brown et al., 2020, OpenAI, 2023 ] , the LLama series models [ Touvron et al., 2023 ] , Gemini [ Google, 2023 ] , and other large language models demonstrate impressive language and knowledge mastery, surpassing human benchmark levels in multiple evaluation benchmarks [ Wang et al., 2019, Hendrycks et al., 2020, Srivastava et al., 2022 ].\n",
      "\n",
      "However, large language models also exhibit numerous shortcomings. They often fabricate facts [ Zhang et al., 2023b ] and lack knowledge when dealing with specific domains or highly specialized queries [ Kandpal et al., 2023 ] . For instance, when the information sought extends beyond the model's training data or requires the latest data, LLM may fail to provide accurate answers. This limitation poses challenges when deploying generative artificial intelligence in real-world production environments, as blindly using a black-box LLM may not suffice.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Traditionally, neural networks adapt to specific domains or proprietary information by fine-tuning models to parameterize knowledge. While this technique yields significant results, it demands substantial computational resources, incurs high costs, and requires specialized technical expertise, making it less adaptable to the evolving information landscape. Parametric knowledge and non-parametric knowledge play distinct roles. Parametric knowledge is acquired through training LLMs and stored in the neural network weights, representing the model's understanding and generalization of the training data, forming the foundation for generated responses. Non-parametric knowledge, on the other hand, resides in external knowledge sources such as vector databases, not encoded directly into the model but treated as updatable supplementary information. Non-parametric knowledge empowers LLMs to access and leverage the latest or domainspecific information, enhancing the accuracy and relevance of responses.\n",
      "\n",
      "Purely parameterized language models (LLMs) store their world knowledge, which is acquired from vast corpora, in the parameters of the model. Nevertheless, such models have their limitations. Firstly, it is difficult to retain all the knowledge from the training corpus, especially for less common and more specific knowledge. Secondly, since the model parameters cannot be updated dynamically, the parametric knowledge is susceptible to becoming outdated over time. Lastly, an expansion in parameters leads to increased computational expenses for both training and inference. To address the limitations of purely parameterized models, language models can adopt a semi-parameterized approach by integrating a non-parameterized corpus database with parameterized models. This approach is known as RetrievalAugmented Generation (RAG).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import common_tools as common_tools\n",
    "\n",
    "test_content = common_tools.read_file('/Users/Daglas/Desktop/暂存数据.md')\n",
    "chunks = common_tools.split_text_by_length(test_content, 2000)\n",
    "print(chunks[0])\n",
    "print('\\n\\n')\n",
    "print(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama)",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
